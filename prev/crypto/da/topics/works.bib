@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{an2024does,
  title={Why Does the Effective Context Length of LLMs Fall Short?},
  author={An, Chenxin and Zhang, Jun and Zhong, Ming and Li, Lei and Gong, Shansan and Luo, Yao and Xu, Jingjing and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2410.18745},
  year={2024}
}

@article{fournier2023practical,
  title={A practical survey on faster and lighter transformers},
  author={Fournier, Quentin and Caron, Ga{\'e}tan Marceau and Aloise, Daniel},
  journal={ACM Computing Surveys},
  volume={55},
  number={14s},
  pages={1--40},
  year={2023},
  publisher={ACM New York, NY}
}

@article{dao2023flashattention,
  title={Flashattention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{li2024long,
  title={Long-context llms struggle with long in-context learning},
  author={Li, Tianle and Zhang, Ge and Do, Quy Duc and Yue, Xiang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2404.02060},
  year={2024}
}
@article{behrouz2024titans,
  title={Titans: Learning to memorize at test time},
  author={Behrouz, Ali and Zhong, Peilin and Mirrokni, Vahab},
  journal={arXiv preprint arXiv:2501.00663},
  year={2024}
}
@inproceedings{ulvcar2021training,
  title={Training dataset and dictionary sizes matter in Bert models: the case of Baltic languages},
  author={Ul{\v{c}}ar, Matej and Robnik-{\v{S}}ikonja, Marko},
  booktitle={International Conference on Analysis of Images, Social Networks and Texts},
  pages={162--172},
  year={2021},
  organization={Springer}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{takase2024large,
  title={Large Vocabulary Size Improves Large Language Models},
  author={Takase, Sho and Ri, Ryokan and Kiyono, Shun and Kato, Takuya},
  journal={arXiv preprint arXiv:2406.16508},
  year={2024}
}

@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{berlyand2021stability,
  title={Stability for the training of deep neural networks and other classifiers},
  author={Berlyand, Leonid and Jabin, Pierre-Emmanuel and Safsten, C Alex},
  journal={Mathematical Models and Methods in Applied Sciences},
  volume={31},
  number={11},
  pages={2345--2390},
  year={2021},
  publisher={World Scientific}
}
@article{weng2021diffusion,
  title   = "What are diffusion models?",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2021",
  month   = "Jul",
  url     = "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
}
@article{yang2023diffusion,
  title={Diffusion models: A comprehensive survey of methods and applications},
  author={Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
  journal={ACM Computing Surveys},
  volume={56},
  number={4},
  pages={1--39},
  year={2023},
  publisher={ACM New York, NY, USA}
}
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{muennighoff2025s1,
  title={s1: Simple test-time scaling},
  author={Muennighoff, Niklas and Yang, Zitong and Shi, Weijia and Li, Xiang Lisa and Fei-Fei, Li and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Liang, Percy and Cand{\`e}s, Emmanuel and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2501.19393},
  year={2025}
}
@article{hyvarinen2005estimation,
  title={Estimation of non-normalized statistical models by score matching.},
  author={Hyv{\"a}rinen, Aapo and Dayan, Peter},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={4},
  year={2005}
}
@article{austin2021structured,
  title={Structured denoising diffusion models in discrete state-spaces},
  author={Austin, Jacob and Johnson, Daniel D and Ho, Jonathan and Tarlow, Daniel and Van Den Berg, Rianne},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={17981--17993},
  year={2021}
}
@article{campbell2022continuous,
  title={A continuous time framework for discrete denoising models},
  author={Campbell, Andrew and Benton, Joe and De Bortoli, Valentin and Rainforth, Thomas and Deligiannidis, George and Doucet, Arnaud},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28266--28279},
  year={2022}
}
@article{hyvarinen2007some,
  title={Some extensions of score matching},
  author={Hyv{\"a}rinen, Aapo},
  journal={Computational statistics \& data analysis},
  volume={51},
  number={5},
  pages={2499--2512},
  year={2007},
  publisher={Elsevier}
}
@article{meng2022concrete,
  title={Concrete score matching: Generalized score matching for discrete data},
  author={Meng, Chenlin and Choi, Kristy and Song, Jiaming and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34532--34545},
  year={2022}
}
@article{lou2023discrete,
  title={Discrete diffusion modeling by estimating the ratios of the data distribution},
  author={Lou, Aaron and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2310.16834},
  year={2023}
}
